{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae884d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5c1ef0",
   "metadata": {},
   "source": [
    "Intro a PyTorch y al final unas conclusiones de acuerdo a lo conceptos de cada celda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047a9d00",
   "metadata": {},
   "source": [
    "**1. Similitud de algunos procesos básicos entre NumPy y PyTorch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d98607a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15,  6])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sumando arrays con np\n",
    "\n",
    "a = np.array([7, 2])\n",
    "b = np.array([8, 4])\n",
    "\n",
    "c = a + b\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19451572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([15,  6])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ahora con PyTorch la misma operacion de arrays\n",
    "\n",
    "a = torch.tensor([7, 2])\n",
    "b = torch.tensor([8, 4])\n",
    "\n",
    "c = a + b\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c841955d",
   "metadata": {},
   "source": [
    "Se Puede Pasar de PyTorch a np y viceverza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9825f454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 5], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([7, 5])\n",
    "\n",
    "# llamando la variable a con np\n",
    "a.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1edabe4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 8], dtype=torch.int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# el caso contrario\n",
    "a = np.array([4, 8])\n",
    "\n",
    "torch.from_numpy(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd68fcfc",
   "metadata": {},
   "source": [
    "Los datos en las 2 librerias se almacenan de la misma manera y no hay costo palpable de rendimiento. PyTorch se ajusta a las bases que ha cimentado NumPy (mas antigua)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dd4e6c",
   "metadata": {},
   "source": [
    "**2. Tensores**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da484cb",
   "metadata": {},
   "source": [
    "Se podría decir que los tensores son una especie de contenedores de números que pueden tener n-dimensiones. \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865a862a",
   "metadata": {},
   "source": [
    " - Creando un Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d818eb23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7, 4],\n",
       "        [5, 1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[7, 4], [5, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42625e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7., 4.],\n",
       "        [5., 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Un Tensor tipo Float\n",
    "torch.FloatTensor([[7, 4], [5, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a576ad06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True],\n",
       "        [True, True]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se puede definir el tipo de tensor, en este caso un boolean\n",
    "torch.tensor([[1, 2], [2, 1]], dtype=torch.bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7874226",
   "metadata": {},
   "source": [
    "> En general se pueden crear una amplia gama de tensores al ser de multiples dimensiones, por ejemplo matrices aletatorias sin la necesidad de hacerlas manualmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd04099a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7249, 0.9664, 0.1503],\n",
       "        [0.5632, 0.0220, 0.7157],\n",
       "        [0.0386, 0.0512, 0.2396],\n",
       "        [0.8824, 0.0411, 0.5275]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84880b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Una matriz random hech de unos\n",
    "torch.ones(4, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed89d7cc",
   "metadata": {},
   "source": [
    "- Operaciones entre tensores con PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e869c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7, 6],\n",
      "        [4, 2]])\n",
      "sum: 19\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[7, 6], [4, 2]])\n",
    "print(x)\n",
    "\n",
    "#suma de tensores\n",
    "print(f'sum: {x.sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6902d2b",
   "metadata": {},
   "source": [
    "Transponer tensores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af6bf57f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7, 4],\n",
       "        [6, 2]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transponiendo un tensor 2D\n",
    "x.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9831020d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obteniendo la forma(shape) de cada dimension\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd308975",
   "metadata": {},
   "source": [
    "Cuando se realizan operaciones entre tensores generalemnte se forma uno nuevo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "670c92fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8, 8],\n",
       "        [9, 3]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.tensor([[1, 2], [5, 1]])\n",
    "z = x.add(y)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77d322a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8, 8],\n",
       "        [9, 3]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se puede hacer in-place (de forma local) con el mismo resultado\n",
    "# casi todas las operaciones se pueden hacer de esta forma (nombre de la operacion mas un _)\n",
    "x.add_(y)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1124cb6b",
   "metadata": {},
   "source": [
    "# Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2142e3",
   "metadata": {},
   "source": [
    "Algunas consideraciones finales del por que puede ser una ventaja trabajar con PyTorch: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcb5fc2",
   "metadata": {},
   "source": [
    "**PyTorch se puede correr en GPU`s por lo que lo hace muy potente a la hora de trabajar con modelos que necesiten muchos datos (a comparación de NumPy).** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4f4d987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Para saber si hay GPU disponible. Google colab ofrece en sus servicios GPUs con las que se puede trabajar gratuitamente.\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4ec392",
   "metadata": {},
   "source": [
    ">Los tensores se pueden guardar en CUDA para trabajarlos desde ahi. No se permite hacer operaciones entre Tensores GPU y CPU "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57327d31",
   "metadata": {},
   "source": [
    "Tiene un diferenciador llamado **Autograd** el cual impulsa y optimiza el entrenamiento de las redes neuronales.\n",
    "Recordemos que las redes neuronales (NN) son una colección de funciones anidadas que se ejecutan en algunos datos de entrada (inputs). Estas funciones están definidas por parámetros (que consisten en pesos (weights) y sesgos (biases), que en PyTorch se almacenan en tensores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c581c8",
   "metadata": {},
   "source": [
    "El conjunto de herramientas para construir redes neuronales (NN) es muy robusto e incluye varios paquetes para trabajar con texto (NLP) o imagenes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef9d5eb",
   "metadata": {},
   "source": [
    "Es importante tener claros conceptos generales y como se nombran en inglés."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9b954c",
   "metadata": {},
   "source": [
    "Como Bonus se puede mencionar La discrepancia de tamaño entre los tensores ocurre con frecuencia y (casi siempre) es fácil de solucionar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0538235",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15436/180995250.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0ma\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "a = torch.ones(2, 2) \n",
    "b = torch.ones(1, 3)\n",
    "a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1581ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5b73ec33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9ed2d9",
   "metadata": {},
   "source": [
    "Se pueden Imprimir los tamaños para estar completamente seguro de las operaciones que se pueden hacer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2395906e",
   "metadata": {},
   "source": [
    "**A parte de PyTorch existen otras opciones muy validas como Tensorflow o Keras, para ampliar el espectro no estaría de mas revisarlas despues de tener bases solidas con Pytorch que considero en este repo, aunque \"nunca hay que casarse con una sola tecnología!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cdbc90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
